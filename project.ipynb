{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Applied Statistics - Winter 2024 (40%)\n",
    "Lecturer: Ian McLoughlin\n",
    "Author: Lais Coletta Pereira\n",
    "\n",
    "Your task is to perform t-tests and ANOVA on this dataset while describing the dataset and explaining your work. In doing this you should:\n",
    "\n",
    "1. Download and save the dataset to your repository.\n",
    "\n",
    "2. Describe the data set in your notebook.\n",
    "\n",
    "3. Describe what a t-test is, how it works, and what the assumptions are.\n",
    "\n",
    "4. Perform a t-test to determine whether there is a significant difference between the two treatment groups trt1 and trt2.\n",
    "\n",
    "5. Perform ANOVA to determine whether there is a significant difference between the three treatment groups ctrl, trt1, and trt2.\n",
    "\n",
    "6. Explain why it is more appropriate to apply ANOVA rather than several t-tests when analyzing more than two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marking Scheme\n",
    "Each component will be graded based on the following four categories. Each category carries equal weight.\n",
    "\n",
    "Remember, your repository is what will be evaluated. It should demonstrate evidence of the criteria outlined for each category. That said, the examiners' overall impression of the submission may affect marks in each category.\n",
    "\n",
    "You are expected to make steady progress on the assessment throughout the semester. This should be reflected in your commit history. Huge commits, especially late in the semester, will not be accepted. At any stage you may be asked to discuss the work to date in your repository.\n",
    "\n",
    "If you encounter issues with your repository, seek help well before the deadline. Do not delete any files or commits without first consulting the lecturer.\n",
    "\n",
    "Research\n",
    "Evidence of research on relevant topics.\n",
    "Appropriate referencing.\n",
    "Building upon the literature and documentation.\n",
    "Comparisons to similar work.\n",
    "Development\n",
    "Clear, concise, and correct code.\n",
    "Appropriate tests.\n",
    "Knowledge of different approaches and algorithms.\n",
    "Clean architecture.\n",
    "Documentation\n",
    "Clear explanations of concepts.\n",
    "Concise comments in code and elsewhere.\n",
    "Appropriate README for repository.\n",
    "Consistency\n",
    "Tens of commits, each representing a reasonable amount of work.\n",
    "Literature, documentation, and code evidencing work on the assessment.\n",
    "Evidence of reviewing and refactoring.\n",
    "Advice\n",
    "The freedom provided in open-style assessments such as this one can feel challenging. You need to decide how to start, what content to include, how much to cover, and how to make the work your own.\n",
    "\n",
    "The assessment is designed to provide you with opportunities for independent thinking and decision-making. Employers value graduates who can take initiative, work independently, and make design decisions with minimal guidance. We expect you to have basic programming knowledge and be able to find information on your own.\n",
    "\n",
    "You should have a clear plan before you start coding. Your submission should include both your plan and an explanation of any design choices you made.\n",
    "\n",
    "Make sure to follow ATU's policies and regulations which are on the Student Hub. Pay particular attention to any policies on plagiarism and the Student Code. If you're unsure about anything, ask the lecturer.\n",
    "\n",
    "1. Download and Load the Dataset\n",
    "\n",
    "2. Describe the Dataset\n",
    "\n",
    "3. What is a t-test?\n",
    "A t-test is a statistical test used to determine whether there is a significant difference between the means of two groups. There are two main types of t-tests:\n",
    "\n",
    "Independent samples t-test: Compares means of two independent groups.\n",
    "Paired samples t-test: Compares means from the same group at two different times.\n",
    "How It Works\n",
    "Computes the t-statistic, which measures the difference between group means relative to the variation in the data.\n",
    "Compares the t-statistic to a critical value from the t-distribution to decide whether the difference is statistically significant.\n",
    "Assumptions\n",
    "The data is continuous.\n",
    "The data follows a normal distribution (or the sample size is large enough for the Central Limit Theorem to apply).\n",
    "The two groups have approximately equal variances.\n",
    "Observations are independent.\n",
    "4. Performing t-test on trt1 and trt2\n",
    "We will check if there is a significant difference in plant weights between trt1 and trt2.\n",
    "\n",
    "5. What is ANOVA?\n",
    "Analysis of Variance (ANOVA) is used to determine whether there are statistically significant differences between the means of three or more groups.\n",
    "\n",
    "How It Works\n",
    "Partition total variation in the data into \"between-group\" and \"within-group\" variances.\n",
    "Calculates the F-statistic, which is the ratio of between-group variance to within-group variance.\n",
    "Compares the F-statistic to a critical value from the F-distribution.\n",
    "Assumptions\n",
    "The data follows a normal distribution.\n",
    "Homogeneity of variances across groups.\n",
    "Observations are independent.\n",
    "6. Why Use ANOVA Instead of Multiple t-tests?\n",
    "Increased Error Rate: Conducting multiple t-tests increases the likelihood of Type I errors (false positives) because each test has its own significance threshold.\n",
    "Holistic Approach: ANOVA considers all group comparisons simultaneously, providing a single test statistic.\n",
    "Efficiency: ANOVA is computationally more efficient and interprets overall group differences in one step.\n",
    "7. Performing ANOVA\n",
    "We will determine if there is a significant difference in plant weights between the three groups: ctrl, trt1, and trt2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import ssl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_1. Download and Load the Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'Applied-Statistics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/laiscoletta/Desktop/DA Final Semester/Applied-Statistics/project.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/laiscoletta/Desktop/DA%20Final%20Semester/Applied-Statistics/project.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m save_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mApplied-Statistics/plantgrowth.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/laiscoletta/Desktop/DA%20Final%20Semester/Applied-Statistics/project.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Save the dataset to the specified path\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/laiscoletta/Desktop/DA%20Final%20Semester/Applied-Statistics/project.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(save_path, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/laiscoletta/Desktop/DA%20Final%20Semester/Applied-Statistics/project.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset successfully saved to \u001b[39m\u001b[39m{\u001b[39;00msave_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3968\u001b[0m     path_or_buf,\n\u001b[1;32m   3969\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3970\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3971\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3972\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3973\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3974\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3975\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3976\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3977\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3978\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3979\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3980\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3981\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3982\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3983\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3984\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    254\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    255\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    256\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    257\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    258\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    751\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'Applied-Statistics'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/PlantGrowth.csv\"\n",
    "\n",
    "# Load the dataset from the URL\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Define the path to save the dataset inside your 'Applied-Statistics' folder\n",
    "save_path = \"Applied-Statistics/plantgrowth.csv\"\n",
    "\n",
    "# Save the dataset to the specified path\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Dataset successfully saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/Desktop/DA Final Semester/Applied-Statistics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/laiscoletta/Desktop/DA Final Semester/Applied-Statistics/project.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/laiscoletta/Desktop/DA%20Final%20Semester/Applied-Statistics/project.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m save_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Desktop/DA Final Semester/Applied-Statistics/plantgrowth.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/laiscoletta/Desktop/DA%20Final%20Semester/Applied-Statistics/project.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Save the dataset to the specified path\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/laiscoletta/Desktop/DA%20Final%20Semester/Applied-Statistics/project.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(save_path, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/laiscoletta/Desktop/DA%20Final%20Semester/Applied-Statistics/project.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset successfully saved to \u001b[39m\u001b[39m{\u001b[39;00msave_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3968\u001b[0m     path_or_buf,\n\u001b[1;32m   3969\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3970\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3971\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3972\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3973\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3974\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3975\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3976\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3977\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3978\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3979\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3980\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3981\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3982\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3983\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3984\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    254\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    255\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    256\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    257\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    258\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    751\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/Desktop/DA Final Semester/Applied-Statistics'"
     ]
    }
   ],
   "source": [
    "# Disable SSL verification (for development purposes only)\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/PlantGrowth.csv\"\n",
    "\n",
    "# Load the dataset from the URL\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Define the path to save the dataset inside the 'Applied-Statistics' folder\n",
    "save_path = \"/Desktop/DA Final Semester/Applied-Statistics/plantgrowth.csv\"\n",
    "\n",
    "# Save the dataset to the specified path\n",
    "df.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Dataset successfully saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Describe the data set in your notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(plant_growth.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations: \n",
    "1. The weight variable shows moderate variability (std = 0.701), with weights ranging from 3.59 to 6.31 grams.\n",
    "2. The median weight (5.155) is close to the mean (5.073), indicating a symmetric distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   rownames  30 non-null     int64  \n",
      " 1   weight    30 non-null     float64\n",
      " 2   group     30 non-null     object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 848.0+ bytes\n",
      "\n",
      "Missing Values in Dataset:\n",
      "No missing values detected. \n",
      "\n",
      "\n",
      "Frequency Distribution for 'group' (Categorical Variable):\n",
      "group\n",
      "ctrl    10\n",
      "trt1    10\n",
      "trt2    10\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "\n",
      "Dataset Description:\n",
      "\n",
      "The PlantGrowth dataset consists of 30 observations and 3 columns:\n",
      "1. 'weight': A numerical variable representing the weight of plants.\n",
      "   - Range: 3.59 to 6.31 grams\n",
      "   - Mean: 5.073 grams\n",
      "   - Standard Deviation: 0.701 grams\n",
      "2. 'group': A categorical variable with three treatment groups:\n",
      "   - Control group ('ctrl'): 10 observations\n",
      "   - Treatment 1 ('trt1'): 10 observations\n",
      "   - Treatment 2 ('trt2'): 10 observations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More detailed dataset description\n",
    "# Dataset overview\n",
    "print(\"\\nDataset Information:\")\n",
    "plant_growth.info()  # This automatically prints out column types and non-null counts\n",
    "\n",
    "# Check for missing values and report if any\n",
    "missing_values = plant_growth.isnull().sum()\n",
    "print(\"\\nMissing Values in Dataset:\")\n",
    "print(missing_values if missing_values.any() else \"No missing values detected.\", \"\\n\")\n",
    "\n",
    "# Summary for categorical variables\n",
    "print(\"\\nFrequency Distribution for 'group' (Categorical Variable):\")\n",
    "print(plant_growth['group'].value_counts(), \"\\n\")\n",
    "\n",
    "print(\"\\nDataset Description:\")\n",
    "print(f\"\"\"\n",
    "The PlantGrowth dataset consists of {len(plant_growth)} observations and {plant_growth.shape[1]} columns:\n",
    "1. 'weight': A numerical variable representing the weight of plants.\n",
    "   - Range: {plant_growth['weight'].min()} to {plant_growth['weight'].max()} grams\n",
    "   - Mean: {plant_growth['weight'].mean():.3f} grams\n",
    "   - Standard Deviation: {plant_growth['weight'].std():.3f} grams\n",
    "2. 'group': A categorical variable with three treatment groups:\n",
    "   - Control group ('ctrl'): {plant_growth['group'].value_counts()['ctrl']} observations\n",
    "   - Treatment 1 ('trt1'): {plant_growth['group'].value_counts()['trt1']} observations\n",
    "   - Treatment 2 ('trt2'): {plant_growth['group'].value_counts()['trt2']} observations\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
